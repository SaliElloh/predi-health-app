# predi-health-app
A real-time diagnostic and predictive application that collects and evaluates data from your Fitbit watch.

For more information about me, please visit my LinkedIn:

[![LinkedIn][LinkedIn.js]][LinkedIn-url]

<!-- ABOUT THE PROJECT -->

## About The Project:

### Introduction:


## Getting Started:

To get the project running, there's a few programs and steps needed.

### Built With:

* <img src="https://img.shields.io/badge/-Python-3776AB?style=flat&logo=python&logoColor=white">
* <img src="https://img.shields.io/badge/-Flutter-02569B?style=flat&logo=flutter&logoColor=white">
* <img src="https://img.shields.io/badge/-FastAPI-009688?style=flat&logo=fastapi&logoColor=white">
* <img src="https://img.shields.io/badge/-Redis-DC382D?style=flat&logo=redis&logoColor=white">
* <img src="https://img.shields.io/badge/-TensorFlow-FF6F00?style=flat&logo=tensorflow&logoColor=white">


## Demo:

<!-- CONTACT -->
## Contact:

Sali E-loh - [@Sali El-loh](https://www.linkedin.com/in/salielloh12/) - ellohsali@gmail.com

# Description:
This repository contains Jupyter notebooks for analyzing emotions in conversations using natural language processing techniques. The project is part of SemEval 2024 Task 3: The Competition of Multimodal Emotion Cause Analysis in Conversations.

## Files:

### text_analysis.ipynb:

* This notebook focuses on text-based emotion recognition.
* Implements baseline statistical models such as Naive Bayes, Random Forest, Decision Tree, and Support Vector Machine for emotion classification using text data.
* Explores various preprocessing techniques like tokenization, lemmatization, and stop word removal.
* Evaluates models based on F1 scores for individual emotions and a weighted average.

### audio_analysis.ipynb:

* This notebook aims to analyze emotions in conversations using audio data.
* Implements audio feature extraction techniques such as Mel-frequency cepstral coefficients (MFCCs) and pitch.
* Utilizes machine learning models like SVM and neural networks for emotion classification based on audio features.
* Evaluates model performance using metrics such as accuracy and confusion matrices.

### base_model.ipynb:

* This notebook serves as the baseline model for emotion recognition in conversations.
* Implements a basic statistical model (e.g., logistic regression) for emotion classification.
* Provides a starting point for comparing the performance of more advanced models implemented in other notebooks.
* Contains essential preprocessing steps and data visualization techniques for understanding the dataset.
* 
### Instructions:

Run each notebook individually to understand the specific analysis and implementation.
Ensure all necessary libraries and dependencies are installed before running the notebooks.
Experiment with different models, preprocessing techniques, and feature engineering methods to improve performance.

### Contributors:
* Anika Raisa-Chowdhury
* Tanvi Shah
* Sali El-Loh
* Seoyoung Kim
* Dawson Kinsman

### Note:

Future work involves integrating text, audio, and potentially video data for multimodal emotion recognition.






